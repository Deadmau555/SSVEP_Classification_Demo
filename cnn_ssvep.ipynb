{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from numpy import matlib as mb\n",
    "\n",
    "import utils.cca_utils as su\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_PARAMS = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'droprate': 0.25,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay': 0.0,\n",
    "    'l2_lambda': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    'kernel_f': 10,\n",
    "    'n_ch': 8,\n",
    "    'num_classes': 12}\n",
    "\n",
    "FFT_PARAMS = {\n",
    "    'resolution': 0.2930,\n",
    "    'start_frequency': 3.0,\n",
    "    'end_frequency': 35.0,\n",
    "    'sampling_rate': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1  - Accuracy: [77.77777791] %\n",
      "Subject: 2  - Accuracy: [56.80555582] %\n",
      "Subject: 3  - Accuracy: [94.99999881] %\n",
      "Subject: 4  - Accuracy: [98.19444358] %\n",
      "Subject: 5  - Accuracy: [99.72222209] %\n",
      "Subject: 6  - Accuracy: [99.72222209] %\n",
      "Subject: 7  - Accuracy: [94.16666687] %\n",
      "Subject: 8  - Accuracy: [99.16666627] %\n",
      "Subject: 9  - Accuracy: [97.36110985] %\n",
      "Subject: 10  - Accuracy: [89.86111045] %\n",
      ".....................................................................................\n",
      "Overall Accuracy Across Subjects: 90.77777737379074 % std: 12.969158303635055 %\n",
      ".....................................................................................\n"
     ]
    }
   ],
   "source": [
    "all_acc = np.zeros((10, 1))\n",
    "\n",
    "for subject in range(0, 10):\n",
    "\n",
    "    dataset = sio.loadmat(f'data/s{subject+1}.mat')\n",
    "    eeg = np.array(dataset['eeg'], dtype='float32')\n",
    "    \n",
    "    CNN_PARAMS['num_classes'] = eeg.shape[0]\n",
    "    CNN_PARAMS['n_ch'] = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "    sample_rate = 256\n",
    "\n",
    "    filtered_data = su.get_filtered_eeg(eeg, 6, 80, 4, sample_rate)\n",
    "    eeg = []\n",
    "\n",
    "    window_len = 1 \n",
    "    shift_len = 1\n",
    "    \n",
    "    segmented_data = su.get_segmented_epochs(filtered_data, window_len, shift_len, sample_rate)\n",
    "    filtered_data = []\n",
    "     \n",
    "    features_data = su.complex_spectrum_features(segmented_data, FFT_PARAMS)\n",
    "    segmented_data = []\n",
    "    \n",
    "    #Combining the features into a matrix of dim [features X channels X classes X trials*segments]\n",
    "    features_data = np.reshape(features_data, (features_data.shape[0], features_data.shape[1], \n",
    "                                               features_data.shape[2], features_data.shape[3]*features_data.shape[4]))\n",
    "    \n",
    "    train_data = features_data[:, :, 0, :].T\n",
    "    #Reshaping the data into dim [classes*trials*segments X channels X features]\n",
    "    for target in range(1, features_data.shape[2]):\n",
    "        train_data = np.vstack([train_data, np.squeeze(features_data[:, :, target, :]).T])\n",
    "\n",
    "    #Finally reshaping the data into dim [classes*trials*segments X channels X features X 1]    \n",
    "    train_data = np.reshape(train_data, (train_data.shape[0], train_data.shape[1], train_data.shape[2], 1))\n",
    "    \n",
    "    total_epochs_per_class = features_data.shape[3]\n",
    "    features_data = []\n",
    "    \n",
    "    class_labels = np.arange(CNN_PARAMS['num_classes'])\n",
    "    labels = (mb.repmat(class_labels, total_epochs_per_class, 1).T).ravel()\n",
    "    labels = to_categorical(labels)\n",
    "\n",
    "    num_folds = 10\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "    kf.get_n_splits(train_data)\n",
    "    cv_acc = np.zeros((num_folds, 1))\n",
    "    fold = -1\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_data):\n",
    "        x_tr, x_ts = train_data[train_index], train_data[test_index]\n",
    "        y_tr, y_ts = labels[train_index], labels[test_index]\n",
    "        input_shape = np.array([x_tr.shape[1], x_tr.shape[2], x_tr.shape[3]])\n",
    "        \n",
    "        fold = fold + 1\n",
    "        # print(\"Subject:\", subject+1, \"Fold:\", fold+1, \"Training...\")\n",
    "        \n",
    "        model = su.CNN_model(input_shape, CNN_PARAMS)\n",
    "        \n",
    "        sgd = optimizers.SGD(lr=CNN_PARAMS['learning_rate'], decay=CNN_PARAMS['lr_decay'], \n",
    "                             momentum=CNN_PARAMS['momentum'], nesterov=False)\n",
    "        model.compile(loss=categorical_crossentropy, optimizer=sgd, metrics=[\"accuracy\"])\n",
    "        history = model.fit(x_tr, y_tr, batch_size=CNN_PARAMS['batch_size'], \n",
    "                            epochs=CNN_PARAMS['epochs'], verbose=0)\n",
    "\n",
    "        score = model.evaluate(x_ts, y_ts, verbose=0) \n",
    "        cv_acc[fold, :] = score[1]*100\n",
    "        # print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "    \n",
    "    all_acc[subject] = np.mean(cv_acc)\n",
    "    # print(\"...................................................\")\n",
    "    print(\"Subject:\", subject+1, \" - Accuracy:\", all_acc[subject],\"%\")\n",
    "    # print(\"...................................................\")\n",
    "\n",
    "print(\".....................................................................................\")\n",
    "print(\"Overall Accuracy Across Subjects:\", np.mean(all_acc), \"%\", \"std:\", np.std(all_acc), \"%\")\n",
    "print(\".....................................................................................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('Brain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbb31b57882cabf08ac03ea0d3d9d5f6f2c94eb28645c63d834ff021c0c44a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
