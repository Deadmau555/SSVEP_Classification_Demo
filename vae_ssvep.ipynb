{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from numpy import matlib as mb\n",
    "\n",
    "import utils.cca_utils as su\n",
    "import utils.vae_utils as va\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "data_path = os.path.abspath('data')\n",
    "all_segment_data = dict()\n",
    "window_len = 1\n",
    "shift_len = 1\n",
    "sample_rate = 256\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "duration = int(window_len*sample_rate)\n",
    "flicker_freq = np.array([9.25, 11.25, 13.25, 9.75, 11.75, 13.75, \n",
    "                       10.25, 12.25, 14.25, 10.75, 12.75, 14.75])\n",
    "\n",
    "\n",
    "CNN_PARAMS = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'droprate': 0.25,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay': 0.0,\n",
    "    'l2_lambda': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    'kernel_f': 10,\n",
    "    'n_ch': 8,\n",
    "    'num_classes': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the need data by CNN_Classifier\n",
    "def get_CNN_data(features_data, CNN_PARAMS):\n",
    "    features_data = features_data.view(features_data.shape[4], features_data.shape[1], features_data.shape[0], -1)\n",
    "    total_epochs_per_class = features_data.shape[3]\n",
    "    \n",
    "    train_data = features_data.view(-1, features_data.shape[1], features_data.shape[0])\n",
    "    features_data = []\n",
    "    \n",
    "    class_labels = torch.arange(CNN_PARAMS['num_classes'])\n",
    "    labels = (mb.repmat(class_labels, total_epochs_per_class, 1).T).ravel()\n",
    "    labels = to_categorical(labels)\n",
    "    return train_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the need data by VAE\n",
    "def get_vae_data(all_segment_data, CNN_PARAMS):\n",
    "    for subject in range(0,CNN_PARAMS[\"kernel_f\"]):\n",
    "        features_data = torch.from_numpy(all_segment_data[f's{subject+1}'])\n",
    "        features_data = features_data.view(features_data.shape[4], features_data.shape[1], features_data.shape[0], -1)\n",
    "        total_epochs_per_class = features_data.shape[3]\n",
    "        \n",
    "        train_data = features_data.view(-1, features_data.shape[1], features_data.shape[0])\n",
    "        features_data = []\n",
    "        \n",
    "        class_labels = torch.arange(CNN_PARAMS['num_classes'])\n",
    "        labels = (mb.repmat(class_labels, total_epochs_per_class, 1).T).ravel()\n",
    "        labels = to_categorical(labels)\n",
    "        if subject == 0:\n",
    "            all_data = train_data\n",
    "            all_labels = torch.from_numpy(labels)\n",
    "        else:\n",
    "            all_data = torch.cat((all_data, train_data), dim=0)\n",
    "            all_labels = torch.cat((all_labels, torch.from_numpy(labels)), dim=0)\n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all egg data\n",
    "def get_segment_data(CNN_PARAMS, sample_rate = 256, window_len = 1, shift_len = 1):\n",
    "    for subject in tqdm(range(0, CNN_PARAMS[\"kernel_f\"])):\n",
    "        dataset = sio.loadmat(f'data/s{subject+1}.mat')\n",
    "        eeg = np.array(dataset['eeg'], dtype='float32')\n",
    "        \n",
    "        num_classes = eeg.shape[0]\n",
    "        n_ch = eeg.shape[1]\n",
    "        total_trial_len = eeg.shape[2]\n",
    "        num_trials = eeg.shape[3]\n",
    "        sample_rate = 256\n",
    "\n",
    "        filtered_data = su.get_filtered_eeg(eeg, 6, 80, 4, sample_rate)\n",
    "        all_segment_data[f's{subject+1}'] = su.get_segmented_epochs(filtered_data, window_len, \n",
    "                                                            shift_len, sample_rate)\n",
    "    return all_segment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialize the vae model\n",
    "vae_model = va.EEG_CNN_VAE()\n",
    "vae_model.apply(va.weights_init) \n",
    "vae_optimizer = torch.optim.Adam(vae_model.parameters(), lr=0.000003)   \n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "# get processed data\n",
    "all_segment_data = get_segment_data(CNN_PARAMS, sample_rate)\n",
    "# prepare the data needed by vae \n",
    "vae_data, vae_labels = get_vae_data(all_segment_data, CNN_PARAMS)\n",
    "\n",
    "vae_dataset = torch.utils.data.TensorDataset(vae_data, vae_labels)\n",
    "vae_dataloader = torch.utils.data.DataLoader(dataset=vae_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10] Loss: 0.816475 0.698712 0.117763\n",
      "Epoch[2/10] Loss: 0.806127 0.706322 0.099805\n",
      "Epoch[3/10] Loss: 0.812146 0.706866 0.105280\n",
      "Epoch[4/10] Loss: 0.795058 0.691965 0.103093\n",
      "Epoch[5/10] Loss: 0.803683 0.702048 0.101634\n",
      "Epoch[6/10] Loss: 0.777582 0.694609 0.082972\n",
      "Epoch[7/10] Loss: 0.770191 0.699866 0.070325\n",
      "Epoch[8/10] Loss: 0.762445 0.693452 0.068993\n",
      "Epoch[9/10] Loss: 0.768639 0.688958 0.079681\n",
      "Epoch[10/10] Loss: 0.749364 0.684828 0.064536\n"
     ]
    }
   ],
   "source": [
    "# train vae model\n",
    "vae_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(vae_dataloader, 0):\n",
    "        data, labels = data\n",
    "        data = data.type(Tensor)\n",
    "        \n",
    "        vae_optimizer.zero_grad()\n",
    "        recon_data, mu, logvar = vae_model(data)   \n",
    "        vae_loss, bce, kld = va.loss_fn(recon_data, data, mu, logvar)\n",
    "\n",
    "        vae_loss.backward()\n",
    "        vae_optimizer.step()\n",
    "\n",
    "    to_print = \"Epoch[{}/{}] Loss: {:.6f} {:.6f} {:.6f}\".format(epoch+1, num_epochs, vae_loss.item(), bce.item(), kld.item())\n",
    "    print(to_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................\n",
      "Subject: 1  - Accuracy: [99.86111104] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 2  - Accuracy: [99.72222209] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 3  - Accuracy: [99.86111104] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 4  - Accuracy: [100.] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 5  - Accuracy: [99.86111104] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 6  - Accuracy: [99.02777731] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 7  - Accuracy: [100.] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 8  - Accuracy: [100.] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 9  - Accuracy: [99.02777731] %\n",
      "...................................................\n",
      "...................................................\n",
      "Subject: 10  - Accuracy: [99.44444418] %\n",
      "...................................................\n",
      ".....................................................................................\n",
      "Overall Accuracy Across Subjects: 99.68055540323257 % std: 0.3624442936795993 %\n",
      ".....................................................................................\n"
     ]
    }
   ],
   "source": [
    "# train CNN_Classifier\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "with torch.no_grad():\n",
    "    vae_model.eval()\n",
    "\n",
    "    num_folds = 10\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    all_acc = np.zeros((10, 1))\n",
    "    \n",
    "    for subject in range(0,10):\n",
    "        features_data = torch.from_numpy(all_segment_data[f's{subject+1}'])\n",
    "        cnn_data, cnn_labels = get_CNN_data(features_data, CNN_PARAMS)\n",
    "        kf.get_n_splits(cnn_data)\n",
    "        cv_acc = np.zeros((num_folds, 1))\n",
    "        fold = -1\n",
    "    \n",
    "        for train_index, test_index in kf.split(cnn_data):\n",
    "            x_tr, x_ts = cnn_data[train_index], cnn_data[test_index]\n",
    "            y_tr, y_ts = cnn_labels[train_index], cnn_labels[test_index]\n",
    "        \n",
    "            hx_tr = vae_model.hidden_encode(x_tr.type(Tensor))\n",
    "            hx_ts = vae_model.hidden_encode(x_ts.type(Tensor))\n",
    "            \n",
    "            vhx_tr = hx_tr.view(hx_tr.shape[0], hx_tr.shape[1], hx_tr.shape[2], 1)\n",
    "            vhx_ts = hx_ts.view(hx_ts.shape[0], hx_ts.shape[1], hx_ts.shape[2], 1)\n",
    "\n",
    "            input_shape = np.array([vhx_tr.shape[1], vhx_tr.shape[2], vhx_tr.shape[3]])\n",
    "\n",
    "\n",
    "            fold = fold + 1\n",
    "            # print(\"Subject:\", subject+1, \"Fold:\", fold+1, \"Training...\")\n",
    "            \n",
    "            cnn_model = su.CNN_model(input_shape, CNN_PARAMS)\n",
    "            \n",
    "            sgd = optimizers.SGD(lr=CNN_PARAMS['learning_rate'], decay=CNN_PARAMS['lr_decay'], \n",
    "                                momentum=CNN_PARAMS['momentum'], nesterov=False)\n",
    "            cnn_model.compile(loss=categorical_crossentropy, optimizer=sgd, metrics=[\"accuracy\"])\n",
    "            history = cnn_model.fit(vhx_tr.numpy(), y_tr, batch_size=CNN_PARAMS['batch_size'], \n",
    "                                epochs=CNN_PARAMS['epochs'], verbose=0)\n",
    "\n",
    "            score = cnn_model.evaluate(vhx_ts.numpy(), y_ts, verbose=0) \n",
    "            cv_acc[fold, :] = score[1]*100\n",
    "            # print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], score[1]*100))\n",
    "        \n",
    "        all_acc[subject] = np.mean(cv_acc)\n",
    "        print(\"...................................................\")\n",
    "        print(\"Subject:\", subject+1, \" - Accuracy:\", all_acc[subject],\"%\")\n",
    "        print(\"...................................................\")\n",
    "\n",
    "print(\".....................................................................................\")\n",
    "print(\"Overall Accuracy Across Subjects:\", np.mean(all_acc), \"%\", \"std:\", np.std(all_acc), \"%\")\n",
    "print(\".....................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('Brain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbb31b57882cabf08ac03ea0d3d9d5f6f2c94eb28645c63d834ff021c0c44a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
